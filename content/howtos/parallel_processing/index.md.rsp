# How to: Process data in parallel

Author: Henrik Bengtsson  
Created on: 2016-01-11


Parallel processing is supported in Aroma since January 2016 with the release of aroma.affymetrix 3.0.0.  The default is to process data sequentially (synchronously), but with a single change in setting, it is possible to process data in parallel (asynchroneously) on the current machine or on a cluster of compute node.  The mechanism for synchronously/asynchronously processing is automatically handled by the [future] package.

As shown below, the `future::plan()` function can be used to control how data is processed.  I suggest that you add this to your `~/.Rprofile` file, or to a project-specific one `./.Rprofile` in the working directory.  This way you don't have to edit your scripts and therefore they should be able to run anywhere regardless of computational resources.


## Sequential processing
The default is _single-core processing_ via synchronous "eager" futures. This can be explicit set as:
```r
future::plan("eager")
```

## Multicore processing
To process data using _multiple cores_ on the current machine, make sure to call the following first:
```r
future::plan("multicore")
```
That's it!  After this, methods in Aroma that supports parallel processing will automatically process the data in parallel.

The number of cores utilized is given by `future::availableCores()`.  This function looks at a set of commonly used R options and system environment variables to infer the number of core available / assigned to the R session.  If no such settings are available, it will fall back to the total number of cores available on the machine as reported by `parallel::detectCores()`.  The easiest way to control these settings is to use `options(mc.cores=n)`.  See `help("availableCores", package="future")` for more details.

Unfortunately, on Windows, R does not support multicore processing and will therefore fall back to use a single core.  An alternative is to instead use multisession processing.


## Multisession processing
To process data using _multiple R sessions running in the background_ on the current machine, use:
```r
future::plan("multisession")
```
The number of background sessions used is given by `future::availableCores()` just as for multicore processing above.

_NOTE_: Support for multisession processing will be added to future 0.11.0, which is yet to be released on CRAN.  For early access, install it as `source("http://callr.org/install#HenrikBengtsson/future@0.11.0-beta")`.


## Ad hoc cluster processing
To process data using _multiple R sessions running on different machines_, use something like:
```r
hosts <- c("n1", "n4", "n4", "n6", "n7")
cl <- parallel::makeCluster(hosts)
future::plan("cluster", cluster=cl)
```

_NOTE_: Support for multisession processing will be added to future 0.11.0, which is yet to be released on CRAN.  For early access, install it as `source("http://callr.org/install#HenrikBengtsson/future@0.11.0-beta")`.


## Job scheduler processing
Some of you have access to compute clusters with job schedulers such as Torque/PBS and Slurm.  Work is being done to support these type of environments as well and lots of testing is done internally.  However, we do not feel we're ready to release support for this just yet, but as soon as we are, we'll announce it.


[future]: https://cran.r-project.org/package=future
